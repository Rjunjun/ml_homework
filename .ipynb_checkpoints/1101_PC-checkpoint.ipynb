{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEerW5NnDBI6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils, plot_model\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWs8xb6RFvMG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images size : 2528\n"
     ]
    }
   ],
   "source": [
    "#test_images_path = '/content/drive/My Drive/Colab Notebooks/AOI/test_images'\n",
    "#test_images = os.listdir(test_images_path)\n",
    "train_images_path = 'train_images'\n",
    "train_images = os.listdir(train_images_path) \n",
    "#print(\"test_images size :\",len(test_images))\n",
    "print(\"train_images size :\",len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ddu8VfN4HUSp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "#確定train_data裡的IMG是否為一樣大小\n",
    "for i in train_images[:2] :\n",
    "    img = cv2.imread(train_images_path+\"/\"+i)\n",
    "    print(img.shape)\n",
    "    if img.shape != (512,512,3) :\n",
    "        print('ee')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGaxMSL-Os8T"
   },
   "outputs": [],
   "source": [
    "train_images.sort()\n",
    "trainDataPaths = []\n",
    "for i in train_images:\n",
    "    trainDataPaths.append(train_images_path+\"/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a48kV2n1M_Ki"
   },
   "outputs": [],
   "source": [
    "pixel_depth = 255.0\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, 512, 512, 3), dtype=np.float32)\n",
    "\n",
    "    for i, image_file in enumerate(images) :\n",
    "        img = cv2.imread(image_file)\n",
    "        image_data = np.array(img, dtype=np.float32)\n",
    "        #正規化\n",
    "        image_data[:, :, 0] = (image_data[:, :, 0].astype(float) - pixel_depth / 2) / pixel_depth\n",
    "        image_data[:, :, 1] = (image_data[:, :, 1].astype(float) - pixel_depth / 2) / pixel_depth\n",
    "        image_data[:, :, 2] = (image_data[:, :, 2].astype(float) - pixel_depth / 2) / pixel_depth\n",
    "\n",
    "        data[i] = image_data\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processed {} of {}\".format(i, count))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104559,
     "status": "ok",
     "timestamp": 1572551967918,
     "user": {
      "displayName": "賴均杰",
      "photoUrl": "",
      "userId": "02163128368733976250"
     },
     "user_tz": -480
    },
    "id": "5Y_yMPntOZPj",
    "outputId": "8db87434-fcb3-4d84-e237-7d89bfd30d90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 2528\n",
      "Processed 50 of 2528\n",
      "Processed 100 of 2528\n",
      "Processed 150 of 2528\n",
      "Processed 200 of 2528\n",
      "Processed 250 of 2528\n",
      "Processed 300 of 2528\n",
      "Processed 350 of 2528\n",
      "Processed 400 of 2528\n",
      "Processed 450 of 2528\n",
      "Processed 500 of 2528\n",
      "Processed 550 of 2528\n",
      "Processed 600 of 2528\n",
      "Processed 650 of 2528\n",
      "Processed 700 of 2528\n",
      "Processed 750 of 2528\n",
      "Processed 800 of 2528\n",
      "Processed 850 of 2528\n",
      "Processed 900 of 2528\n",
      "Processed 950 of 2528\n",
      "Processed 1000 of 2528\n",
      "Processed 1050 of 2528\n",
      "Processed 1100 of 2528\n",
      "Processed 1150 of 2528\n",
      "Processed 1200 of 2528\n",
      "Processed 1250 of 2528\n",
      "Processed 1300 of 2528\n",
      "Processed 1350 of 2528\n",
      "Processed 1400 of 2528\n",
      "Processed 1450 of 2528\n",
      "Processed 1500 of 2528\n",
      "Processed 1550 of 2528\n",
      "Processed 1600 of 2528\n",
      "Processed 1650 of 2528\n",
      "Processed 1700 of 2528\n",
      "Processed 1750 of 2528\n",
      "Processed 1800 of 2528\n",
      "Processed 1850 of 2528\n",
      "Processed 1900 of 2528\n",
      "Processed 1950 of 2528\n",
      "Processed 2000 of 2528\n",
      "Processed 2050 of 2528\n",
      "Processed 2100 of 2528\n",
      "Processed 2150 of 2528\n",
      "Processed 2200 of 2528\n",
      "Processed 2250 of 2528\n",
      "Processed 2300 of 2528\n",
      "Processed 2350 of 2528\n",
      "Processed 2400 of 2528\n",
      "Processed 2450 of 2528\n",
      "Processed 2500 of 2528\n"
     ]
    }
   ],
   "source": [
    "data = prep_data(trainDataPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3vrv-CgZ40X"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "dfLabel = pd.read_csv('train.csv')\n",
    "np_label = np.array(dfLabel['Label'])\n",
    "np_label = np_utils.to_categorical(np_label)\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data, np_label, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wS_mUTWjLcPQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 512, 512, 16)      1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 36)      14436     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 128, 36)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 128, 36)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 589824)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3538950   \n",
      "=================================================================\n",
      "Total params: 3,554,602\n",
      "Trainable params: 3,554,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_yaml, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(5, 5), padding='same', input_shape=(512, 512, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=36, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = Adam(lr=0.0001)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2022 samples, validate on 506 samples\n",
      "Epoch 1/30\n",
      " - 415s - loss: 0.3169 - accuracy: 0.8668 - val_loss: 0.2999 - val_accuracy: 0.8673\n",
      "Epoch 2/30\n",
      " - 569s - loss: 0.2075 - accuracy: 0.9113 - val_loss: 0.2996 - val_accuracy: 0.8594\n",
      "Epoch 3/30\n",
      " - 532s - loss: 0.1636 - accuracy: 0.9319 - val_loss: 0.2999 - val_accuracy: 0.8712\n",
      "Epoch 4/30\n",
      " - 518s - loss: 0.1204 - accuracy: 0.9542 - val_loss: 0.4096 - val_accuracy: 0.8511\n",
      "Epoch 5/30\n",
      " - 537s - loss: 0.1048 - accuracy: 0.9608 - val_loss: 0.2746 - val_accuracy: 0.8900\n",
      "Epoch 6/30\n",
      " - 545s - loss: 0.0807 - accuracy: 0.9710 - val_loss: 0.3655 - val_accuracy: 0.8762\n",
      "Epoch 7/30\n",
      " - 559s - loss: 0.0710 - accuracy: 0.9736 - val_loss: 0.3023 - val_accuracy: 0.8956\n",
      "Epoch 8/30\n",
      " - 557s - loss: 0.0594 - accuracy: 0.9789 - val_loss: 0.2871 - val_accuracy: 0.9015\n",
      "Epoch 9/30\n",
      " - 596s - loss: 0.0686 - accuracy: 0.9772 - val_loss: 0.2661 - val_accuracy: 0.9042\n",
      "Epoch 10/30\n",
      " - 559s - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.3310 - val_accuracy: 0.8959\n",
      "Epoch 11/30\n",
      " - 542s - loss: 0.0375 - accuracy: 0.9908 - val_loss: 0.3074 - val_accuracy: 0.8995\n",
      "Epoch 12/30\n",
      " - 542s - loss: 0.0359 - accuracy: 0.9896 - val_loss: 0.2651 - val_accuracy: 0.9084\n",
      "Epoch 13/30\n",
      " - 550s - loss: 0.0361 - accuracy: 0.9880 - val_loss: 0.2459 - val_accuracy: 0.9160\n",
      "Epoch 14/30\n",
      " - 590s - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.2263 - val_accuracy: 0.9213\n",
      "Epoch 15/30\n",
      " - 593s - loss: 0.0222 - accuracy: 0.9948 - val_loss: 0.2272 - val_accuracy: 0.9209\n",
      "Epoch 16/30\n",
      " - 569s - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.2445 - val_accuracy: 0.9196\n",
      "Epoch 17/30\n",
      " - 613s - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.2383 - val_accuracy: 0.9282\n",
      "Epoch 18/30\n",
      " - 575s - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.2285 - val_accuracy: 0.9242\n",
      "Epoch 19/30\n",
      " - 611s - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.2306 - val_accuracy: 0.9229\n",
      "Epoch 20/30\n",
      " - 699s - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.2932 - val_accuracy: 0.9107\n",
      "Epoch 21/30\n",
      " - 581s - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.2238 - val_accuracy: 0.9279\n",
      "Epoch 22/30\n",
      " - 576s - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.2428 - val_accuracy: 0.9256\n",
      "Epoch 23/30\n",
      " - 583s - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.2435 - val_accuracy: 0.9209\n",
      "Epoch 24/30\n",
      " - 580s - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.2092 - val_accuracy: 0.9308\n",
      "Epoch 25/30\n",
      " - 620s - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.2229 - val_accuracy: 0.9312\n",
      "Epoch 26/30\n",
      " - 602s - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.2329 - val_accuracy: 0.9285\n",
      "Epoch 27/30\n",
      " - 637s - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.2089 - val_accuracy: 0.9328\n",
      "Epoch 28/30\n",
      " - 615s - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.1836 - val_accuracy: 0.9384\n",
      "Epoch 29/30\n",
      " - 562s - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1777 - val_accuracy: 0.9401\n",
      "Epoch 30/30\n",
      " - 552s - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.1937 - val_accuracy: 0.9354\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x_train, y_train, batch_size=20, epochs=30, verbose=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1101.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
